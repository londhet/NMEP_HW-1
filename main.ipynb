{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from timm.utils import AverageMeter, accuracy\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset  # For custom datasets\n",
    "from tqdm import tqdm\n",
    "from fvcore.nn import FlopCountAnalysis, flop_count_str\n",
    "\n",
    "from config import get_config\n",
    "from data import build_loader\n",
    "from models import build_model\n",
    "from optimizer import build_optimizer\n",
    "from utils import create_logger, load_checkpoint, save_checkpoint\n",
    "\n",
    "\n",
    "def parse_option():\n",
    "    parser = argparse.ArgumentParser(\"Vision model training and evaluation script\", add_help=False)\n",
    "    parser.add_argument(\"--cfg\", type=str, required=True, metavar=\"FILE\", help=\"path to config file\")\n",
    "    parser.add_argument(\"--opts\", help=\"Modify config options by adding 'KEY VALUE' pairs.\", default=None, nargs=\"+\")\n",
    "\n",
    "    # easy config modification\n",
    "    parser.add_argument(\"--batch-size\", type=int, help=\"batch size for single GPU\")\n",
    "    parser.add_argument(\"--data-path\", type=str, help=\"path to dataset\")\n",
    "    parser.add_argument(\"--resume\", help=\"resume from checkpoint\")\n",
    "    parser.add_argument(\n",
    "        \"--output\",\n",
    "        default=\"output\",\n",
    "        type=str,\n",
    "        metavar=\"PATH\",\n",
    "        help=\"root of output folder, the full path is <output>/<model_name>/<tag> (default: output)\",\n",
    "    )\n",
    "    parser.add_argument(\"--eval\", action=\"store_true\", help=\"Perform evaluation only\")\n",
    "    parser.add_argument(\"--throughput\", action=\"store_true\", help=\"Test throughput only\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    config = get_config(args)\n",
    "\n",
    "    return args, config\n",
    "\n",
    "\n",
    "def main(config):\n",
    "    dataset_train, dataset_val, dataset_test, data_loader_train, data_loader_val, data_loader_test = build_loader(\n",
    "        config\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = build_model(config)\n",
    "    # logger.info(str(model))\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # param and flop counts\n",
    "    n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    toy_input = torch.rand(1, 3, config.DATA.IMG_SIZE, config.DATA.IMG_SIZE).to(device) # for measuring flops\n",
    "    flops = FlopCountAnalysis(model, toy_input)\n",
    "    del toy_input\n",
    "\n",
    "    # print(\"Model = %s\" % str(model_without_ddp))\n",
    "    n_flops = flops.total()\n",
    "    logger.info(flop_count_str(flops))\n",
    "    logger.info('number of params: {} M'.format(n_parameters / 1e6))\n",
    "    logger.info(f'flops: {n_flops/1e6} MFLOPS')\n",
    "\n",
    "    # Keep it simple with basic epoch scheduler\n",
    "    optimizer = build_optimizer(config, model)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    lr_scheduler = CosineAnnealingLR(optimizer, config.TRAIN.EPOCHS)\n",
    "\n",
    "    # initialize wandb tracking\n",
    "    wandb.login()\n",
    "    run = wandb.init(\n",
    "        # Set the project where this run will be logged\n",
    "        project=\"test-run-1\",\n",
    "        # Track hyperparameters and run metadata\n",
    "        config={\n",
    "            \"learning_rate\": config.TRAIN.LR,\n",
    "            \"epochs\": config.TRAIN.EPOCHS,\n",
    "        },\n",
    ")\n",
    "\n",
    "    max_accuracy = 0.0\n",
    "\n",
    "    if config.MODEL.RESUME:\n",
    "        max_accuracy = load_checkpoint(config, model, optimizer, lr_scheduler, logger)\n",
    "        acc1, loss = validate(config, data_loader_val, model)\n",
    "        logger.info(f\"Accuracy of the network on the {len(dataset_val)} val images: {acc1:.1f}%\")\n",
    "        if config.EVAL_MODE:\n",
    "            return\n",
    "\n",
    "    logger.info(\"Start training\")\n",
    "    start_time = time.time()\n",
    "    for epoch in range(config.TRAIN.START_EPOCH, config.TRAIN.EPOCHS):\n",
    "        train_acc1, train_loss = train_one_epoch(config, model, criterion, data_loader_train, optimizer, epoch)\n",
    "        logger.info(f\" * Train Acc {train_acc1:.3f} Train Loss {train_loss:.3f}\")\n",
    "        logger.info(f\"Accuracy of the network on the {len(dataset_train)} train images: {train_acc1:.1f}%\")\n",
    "\n",
    "        # train_acc1, _ = validate(config, data_loader_train, model)\n",
    "        val_acc1, val_loss = validate(config, data_loader_val, model)\n",
    "        logger.info(f\" * Val Acc {val_acc1:.3f} Val Loss {val_loss:.3f}\")\n",
    "        logger.info(f\"Accuracy of the network on the {len(dataset_val)} val images: {val_acc1:.1f}%\")\n",
    "\n",
    "        if epoch % config.SAVE_FREQ == 0 or epoch == (config.TRAIN.EPOCHS - 1):\n",
    "            save_checkpoint(config, epoch, model, max_accuracy, optimizer, lr_scheduler, logger)\n",
    "\n",
    "        max_accuracy = max(max_accuracy, val_acc1)\n",
    "        logger.info(f\"Max accuracy: {max_accuracy:.2f}%\\n\")\n",
    "        lr_scheduler.step()\n",
    "\n",
    "\n",
    "        log_stats = {\"epoch\": epoch, \"n_params\": n_parameters, \"n_flops\": n_flops,\n",
    "                     \"train_acc\": train_acc1, \"train_loss\": train_loss, \n",
    "                     \"val_acc\": val_acc1, \"val_loss\": val_loss}\n",
    "\n",
    "        wandb.log(log_stats)\n",
    "        \n",
    "        with open(\n",
    "                os.path.join(config.OUTPUT, \"metrics.json\"), mode=\"a\", encoding=\"utf-8\"\n",
    "            ) as f:\n",
    "                f.write(json.dumps(log_stats) + \"\\n\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    logger.info(\"Training time {}\".format(total_time_str))\n",
    "\n",
    "    logger.info(\"Start testing\")\n",
    "    preds = evaluate(config, data_loader_test, model)\n",
    "    np.save(os.path.join(config.OUTPUT, \"preds.npy\"), preds)\n",
    "    # TODO save predictions to csv in kaggle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(config, model, criterion, data_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "\n",
    "    num_steps = len(data_loader)\n",
    "    batch_time = AverageMeter()\n",
    "    loss_meter = AverageMeter()\n",
    "    acc1_meter = AverageMeter()\n",
    "\n",
    "    start = time.time()\n",
    "    end = time.time()\n",
    "    for idx, (samples, targets) in enumerate(tqdm(data_loader, leave=False)):\n",
    "        samples = samples.cuda(non_blocking=True)\n",
    "        targets = targets.cuda(non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(samples)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        (acc1,) = accuracy(outputs, targets)\n",
    "        loss_meter.update(loss.item(), targets.size(0))\n",
    "        acc1_meter.update(acc1.item(), targets.size(0))\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "    memory_used = torch.cuda.max_memory_allocated() / (1024.0 * 1024.0)\n",
    "    logger.info(\n",
    "        f\"Train: [{epoch}/{config.TRAIN.EPOCHS}]\\t\"\n",
    "        f\"lr {lr:.6f}\\t\"\n",
    "        f\"time {batch_time.val:.4f} ({batch_time.avg:.4f})\\t\"\n",
    "        f\"loss {loss_meter.val:.4f} ({loss_meter.avg:.4f})\\t\"\n",
    "        f\"Acc@1 {acc1_meter.val:.3f} ({acc1_meter.avg:.3f})\\t\"\n",
    "        f\"Mem {memory_used:.0f}MB\"\n",
    "    )\n",
    "    epoch_time = time.time() - start\n",
    "    logger.info(f\"EPOCH {epoch} training takes {datetime.timedelta(seconds=int(epoch_time))}\")\n",
    "    return acc1_meter.avg, loss_meter.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(config, data_loader, model):\n",
    "    with torch.no_grad():\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        model.eval()\n",
    "\n",
    "        batch_time = AverageMeter()\n",
    "        loss_meter = AverageMeter()\n",
    "        acc1_meter = AverageMeter()\n",
    "        end = time.time()\n",
    "        for idx, (images, target) in enumerate(data_loader):\n",
    "            images = images.cuda(non_blocking=True)\n",
    "            target = target.cuda(non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            loss = criterion(output, target)\n",
    "            (acc1,) = accuracy(output, target)\n",
    "\n",
    "            loss_meter.update(loss.item(), target.size(0))\n",
    "            acc1_meter.update(acc1.item(), target.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "        memory_used = torch.cuda.max_memory_allocated() / (1024.0 * 1024.0)\n",
    "        logger.info(\n",
    "            f\"Validate: \\t\"\n",
    "            f\"Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\"\n",
    "            f\"Loss {loss_meter.val:.4f} ({loss_meter.avg:.4f})\\t\"\n",
    "            f\"Acc@1 {acc1_meter.val:.3f} ({acc1_meter.avg:.3f})\\t\"\n",
    "            f\"Mem {memory_used:.0f}MB\"\n",
    "        )\n",
    "    return acc1_meter.avg, loss_meter.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(config, data_loader, model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        for idx, (images, _) in enumerate(tqdm(data_loader)):\n",
    "            images = images.cuda(non_blocking=True)\n",
    "            output = model(images)\n",
    "            preds.append(output.cpu().numpy())\n",
    "        preds = np.concatenate(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    args, config = parse_option()\n",
    "\n",
    "    seed = config.SEED\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # random.seed(seed)\n",
    "\n",
    "    # Make output dir\n",
    "    os.makedirs(config.OUTPUT, exist_ok=True)\n",
    "    logger = create_logger(output_dir=config.OUTPUT, name=f\"{config.MODEL.NAME}\")\n",
    "\n",
    "    path = os.path.join(config.OUTPUT, \"config.yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(config.dump())\n",
    "    logger.info(f\"Full config saved to {path}\")\n",
    "\n",
    "    # print config\n",
    "    logger.info(config.dump())\n",
    "    logger.info(json.dumps(vars(args)))\n",
    "\n",
    "    main(config)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
